{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0unOszRJ56+n12NqPc0DO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onlytolearn/yuce/blob/main/ESMFold_viralLab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##run **ESMFold**\n",
        "%%time\n",
        "from string import ascii_uppercase, ascii_lowercase\n",
        "import hashlib, re, os\n",
        "import numpy as np\n",
        "import torch\n",
        "from jax.tree_util import tree_map\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import softmax\n",
        "import gc\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "def parse_output(output):\n",
        "  pae = (output[\"aligned_confidence_probs\"][0] * np.arange(64)).mean(-1) * 31\n",
        "  plddt = output[\"plddt\"][0,:,1]\n",
        "\n",
        "  bins = np.append(0,np.linspace(2.3125,21.6875,63))\n",
        "  sm_contacts = softmax(output[\"distogram_logits\"],-1)[0]\n",
        "  sm_contacts = sm_contacts[...,bins<8].sum(-1)\n",
        "  xyz = output[\"positions\"][-1,0,:,1]\n",
        "  mask = output[\"atom37_atom_exists\"][0,:,1] == 1\n",
        "  o = {\"pae\":pae[mask,:][:,mask],\n",
        "       \"plddt\":plddt[mask],\n",
        "       \"sm_contacts\":sm_contacts[mask,:][:,mask],\n",
        "       \"xyz\":xyz[mask]}\n",
        "  return o\n",
        "\n",
        "def get_hash(x): return hashlib.sha1(x.encode()).hexdigest()\n",
        "alphabet_list = list(ascii_uppercase+ascii_lowercase)\n",
        "def run_mode(jobName, mySequence):\n",
        "  jobname = jobName #@param {type:\"string\"}\n",
        "  jobname = re.sub(r'\\W+', '', jobname)[:50]\n",
        "\n",
        "  sequence = mySequence #@param {type:\"string\"}\n",
        "  sequence = re.sub(\"[^A-Z:]\", \"\", sequence.replace(\"/\",\":\").upper())\n",
        "  sequence = re.sub(\":+\",\":\",sequence)\n",
        "  sequence = re.sub(\"^[:]+\",\"\",sequence)\n",
        "  sequence = re.sub(\"[:]+$\",\"\",sequence)\n",
        "  copies = 1 #@param {type:\"integer\"}\n",
        "  if copies == \"\" or copies <= 0: copies = 1\n",
        "  sequence = \":\".join([sequence] * copies)\n",
        "  num_recycles = 3 #@param [\"0\", \"1\", \"2\", \"3\", \"6\", \"12\", \"24\"] {type:\"raw\"}\n",
        "  chain_linker = 25\n",
        "  global ID\n",
        "  ID = jobname+\"_\"+get_hash(sequence)[:5]\n",
        "  seqs = sequence.split(\":\")\n",
        "  print(seqs)\n",
        "  lengths = [len(s) for s in seqs]\n",
        "  length = sum(lengths)\n",
        "  print(\"length\",length)\n",
        "\n",
        "  u_seqs = list(set(seqs))\n",
        "  if len(seqs) == 1: mode = \"mono\"\n",
        "  elif len(u_seqs) == 1: mode = \"homo\"\n",
        "  else: mode = \"hetero\"\n",
        "\n",
        "  if \"model\" not in dir() or model_name != model_name_:\n",
        "    if \"model\" in dir():\n",
        "      # delete old model from memory\n",
        "      del model\n",
        "      gc.collect()\n",
        "      if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    model = torch.load(model_name)\n",
        "    model.eval().cuda().requires_grad_(False)\n",
        "    model_name_ = model_name\n",
        "\n",
        "  # optimized for Tesla T4\n",
        "  if length > 700:\n",
        "    model.set_chunk_size(64)\n",
        "  else:\n",
        "    model.set_chunk_size(128)\n",
        "\n",
        "  torch.cuda.empty_cache()\n",
        "  output = model.infer(sequence,\n",
        "                      num_recycles=num_recycles,\n",
        "                      chain_linker=\"X\"*chain_linker,\n",
        "                      residue_index_offset=512)\n",
        "\n",
        "  pdb_str = model.output_to_pdb(output)[0]\n",
        "  output = tree_map(lambda x: x.cpu().numpy(), output)\n",
        "  ptm = output[\"ptm\"][0]\n",
        "  plddt = output[\"plddt\"][0,...,1].mean()\n",
        "  O = parse_output(output)\n",
        "  print(f'ptm: {ptm:.3f} plddt: {plddt:.3f}')\n",
        "  os.system(f\"mkdir -p {ID}\")\n",
        "  prefix = f\"{ID}/ptm{ptm:.3f}_r{num_recycles}_default\"\n",
        "  np.savetxt(f\"{prefix}.pae.txt\",O[\"pae\"],\"%.3f\")\n",
        "  with open(f\"{prefix}.pdb\",\"w\") as out:\n",
        "    out.write(pdb_str)\n",
        "\n",
        "with open(\"Ref_PurA_828.faa\", \"r\") as allProtFile:\n",
        "  temp_seq = []\n",
        "  temp_seqname = \"\"\n",
        "  for i in allProtFile.readlines():\n",
        "    i = i.strip()\n",
        "    if i.startswith(\">\"):\n",
        "      if temp_seq:\n",
        "        print(f\"正在预测{temp_seqname}\")\n",
        "        mySequence = \"\".join(temp_seq)\n",
        "        run_mode(temp_seqname, mySequence)\n",
        "        print(f\"{temp_seqname}预测完成\")\n",
        "        os.system(f\"mv ./{ID}/*.pdb /content/drive/MyDrive/{ID}.pdb\")\n",
        "      temp_seq.clear()\n",
        "      temp_seqname = i.split()[0].replace(\">\", \"\")\n",
        "    else:\n",
        "      temp_seq.append(i)\n",
        "  print(f\"正在预测{temp_seqname}\")\n",
        "  mySequence = \"\".join(temp_seq)\n",
        "  run_mode(temp_seq, mySequence)\n",
        "  print(f\"{temp_seqname}预测完成\")\n",
        "  os.system(f\"mv ./{ID}/*.pdb /content/drive/MyDrive/{ID}.pdb\")"
      ],
      "metadata": {
        "id": "UWMSOyN8ZAzJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}